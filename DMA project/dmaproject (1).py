# -*- coding: utf-8 -*-
"""DMAproject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19eVSzFz5-8BuRKEns9xcLVjtwY9y8ulh
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing the necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

pd.set_option('max_rows', 99999)

df = pd.read_csv('/content/cardekho_updated1 (1).csv')
df.head()

df = df.sample(frac=1)

df.isna().sum()

df['full_name'].value_counts()

df['full_name'].unique().shape

df['new_price'].unique()

# under 10, under 20, under 30, 40, 50 above 50
import math
def extract_prices(row):
  try:
    text = row.replace("New Car (On-Road Price) : Rs.", "")
    if "cr" in text.lower():
      return "above 50"
    text = text.replace(" Lakh*","")
    text = float(text.split("-")[1].strip())
    if text < 10:
      return "Below 10"
    if text < 20:
      return "Below 20"
    if text < 30:
      return "Below 30"
    if text < 40:
      return "Below 40"
    if text > 50:
      return "above 50"
  except Exception as e:
    print(e)
df['new_price_transformed'] = df['new_price'].apply(extract_prices)

df.head()

df.drop(['new_price'], axis = 1, inplace=True)

df.head()

df.dtypes

df.drop(['seller_type', 'fuel_type', 'transmission_type'], axis = 1, inplace = True)

df.head()

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
df['full_name_encoded'] = encoder.fit_transform(df['full_name'])

df.head()

encoder.inverse_transform(df['full_name_encoded'])

df.head()

df['new_price_transformed_encoded'] = encoder.fit_transform(df['new_price_transformed'])

df.head()

df.drop(['full_name', 'new_price_transformed'], axis = 1, inplace =True )

df.head()

df['year_since'] = 2022 - df['year']

df.head()

df.drop(['year'], axis = 1, inplace=True)

df.head()

sns.countplot(df['fuel_type.1'])

sns.heatmap(df.corr())

sns.distplot(df['selling_price'])

sns.boxplot(df['selling_price'])

from sklearn.ensemble import RandomForestRegressor

random_forest = RandomForestRegressor()

df.columns

df['Seats'] = df['Seats'].fillna(4)

X, y = df.iloc[:,1:], df.iloc[:,0]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

model = random_forest.fit(X_train, y_train)

model

model.predict(X_test)

from sklearn import metrics
def evaluate_models(model, X_test, y_test):
  # rmse(Root-mean-square), mae, mse
  y_pred = model.predict(X_test)
  return f'''
  "mean absolute error" -> {metrics.mean_absolute_error(y_test, y_pred)}
  {metrics.mean_squared_error(y_test, y_pred)}
  {metrics.r2_score(y_test, y_pred)}
  '''
def fit_model(model_name, X_train, y_train):
  model = model_name()
  model = model.fit(X_train, y_train)
  return model

evaluate_models(model, X_test, y_test)

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('/content/cardekho_updated1 (1).csv')
X = dataset.iloc[:, 3:-1].values
y = dataset.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,
random_state = 0)

import xgboost as xgb
from sklearn.metrics import mean_squared_error
xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,
                max_depth = 5, alpha = 10, n_estimators = 10)
xg_reg.fit(X_train,y_train)
preds = xg_reg.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, preds))
print("RMSE: %f" % (rmse))

# from sklearn.ensemble import GradientBoostingRegressor

# evaluate_models(/(GradientBoostingRegressor, X_train, y_train), X_test, y_test)

# from sklearn.ensemble import StackingRegressor

# >>> from sklearn.datasets import load_diabetes
# >>> from sklearn.linear_model import RidgeCV
# >>> from sklearn.svm import LinearSVR
# >>> from sklearn.ensemble import RandomForestRegressor
# >>> from sklearn.ensemble import StackingRegressor
# >>> X, y = load_diabetes(return_X_y=True)
# >>> estimators = [
# ...     ('lr', RidgeCV()),
# ...     ('svr', LinearSVR(random_state=42))
# ... ]
# >>> reg = StackingRegressor(
# ...     estimators=estimators,
# ...     final_estimator=RandomForestRegressor(n_estimators=10,
# ...                                           random_state=42)
# ... )
# >>> from sklearn.model_selection import train_test_split
# >>> X_train, X_test, y_train, y_test = train_test_split(
# ...     X, y, random_state=42
# ... )
# >>> reg.fit(X_train, y_train).score(X_test, y_test)

# random search --> preferable
# grid search cv